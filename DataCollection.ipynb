{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED), region_name='us-east-1')\n",
    "entries = s3.list_objects(Bucket='openalex', Marker='data/works', Prefix='data/works/updated_date')['Contents']\n",
    "# get all object filenames\n",
    "data_objects = []\n",
    "for entry in entries:\n",
    "    data_objects.append(entry['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download object file from s3\n",
    "def download_object(s3, obj):\n",
    "    raw = 'datalake/raw'\n",
    "    os.makedirs(raw, exist_ok=True)\n",
    "    file_name = obj.split('/')[-1]\n",
    "    raw_file_path = os.path.join(raw, file_name)\n",
    "    # download gzip file ar raw_file_path\n",
    "    s3.download_file(Bucket='openalex', Key = obj, Filename=raw_file_path)\n",
    "    save_file_name = obj.split('/')[-2].split('=')[-1] + file_name.split('.gz')[0]+'.json'\n",
    "    save_file_path = os.path.join(raw, save_file_name)\n",
    "    # extract data from gzip\n",
    "    with gzip.open(raw_file_path, 'rb') as f_in:\n",
    "        with open(save_file_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    #gzip_file = gzip.GzipFile(raw_file_path, 'rb')\n",
    "    #with open(save_file_path, 'wb') as f_out:\n",
    "    #    f_out.write(gzip_file.read())\n",
    "    # delete zipped file once extracted\n",
    "    os.remove(raw_file_path)\n",
    "    return save_file_path\n",
    "\n",
    "# Get filtered contents\n",
    "def get_object_contents(save_file_name):\n",
    "    # columns which are not required\n",
    "    delcolList = ['doi', \n",
    "                  'title', \n",
    "                  'ids', \n",
    "                  'open_access', \n",
    "                  'biblio', \n",
    "                  'is_paratext', \n",
    "                  'mesh', \n",
    "                  'alternate_host_venues', \n",
    "                  'ngrams_url', \n",
    "                  'abstract_inverted_index', \n",
    "                  'created_date']\n",
    "    \n",
    "    object_content = []\n",
    "    total = 0\n",
    "    filtered = 0\n",
    "    with open(save_file_name) as f:\n",
    "        for row in f:\n",
    "            total += 1\n",
    "            # parse json\n",
    "            r_work = json.loads(row)\n",
    "            # remove extra columns\n",
    "            for col in delcolList:\n",
    "                r_work.pop(col, None)\n",
    "            # apply filter on Computer science concepts and publication_year\n",
    "            if r_work['publication_year'] is not None and  r_work['publication_year'] >= 2010:\n",
    "                concepts = r_work['concepts']\n",
    "                for concept in concepts:\n",
    "                    if concept['display_name'].lower() == 'computer science' or concept['id'] == 'https://openalex.org/c41008148':\n",
    "                        object_content.append(r_work)\n",
    "                        filtered += 1\n",
    "                        break\n",
    "    return object_content, total, filtered\n",
    "\n",
    "# write file to local system\n",
    "def write_file(obj, jsonContent, obj_file_name):\n",
    "    raw = 'datalake/raw'\n",
    "    d = obj.split('/')[-2]\n",
    "    f = obj.split('/')[-1].replace('gz', 'json')\n",
    "    os.makedirs(os.path.join(raw, d), exist_ok=True)\n",
    "    filepath = os.path.join(raw, d, f)\n",
    "    with open(filepath, 'w') as outfile:\n",
    "        json.dump(jsonContent, outfile)\n",
    "    os.remove(obj_file_name)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and process all files one by one\n",
    "logger = 'data_download.log'\n",
    "now = datetime.now()\n",
    "cur_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(logger, 'a') as log:\n",
    "    log.write(f'start_time:{cur_time}\\n{\"==\"*30}\\n')\n",
    "\n",
    "start_time = time.time()\n",
    "start_from = 0\n",
    "for obj in tqdm(data_objects[start_from:]):\n",
    "#for obj in [data_objects[0]]:\n",
    "    obj_file_name = download_object(s3, obj)\n",
    "    object_content, total, filtered = get_object_contents(obj_file_name)\n",
    "    if len(object_content) > 0:\n",
    "        outfilepath = write_file(obj, object_content, obj_file_name)\n",
    "        # total_memory_written += os.path.getsize(outfilepath)\n",
    "        with open(logger, 'a') as log:\n",
    "            log.write(f'{obj} file written at: {outfilepath}, total rows:{total}, rows after filter: {filtered}\\n')\n",
    "    else:\n",
    "        with open(logger, 'a') as log:\n",
    "            log.write(f'{obj} file not written, total rows:{total}, rows after filter: {filtered}\\n')\n",
    "        os.remove(obj_file_name)\n",
    "end_time = time.time()\n",
    "print(f'Log file written at: {os.path.join(os.getcwd(),logger)}')\n",
    "\n",
    "now = datetime.now()\n",
    "cur_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(logger, 'a') as log:\n",
    "    log.write(f'{\"==\"*30}\\nend_time:{cur_time}\\nTotal time taken:{(end_time-start_time)/60} minutes\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6deba854f73701cf96f67599d2e89ceb358b45b5aeac6b72dc7e48ba0a56f3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
